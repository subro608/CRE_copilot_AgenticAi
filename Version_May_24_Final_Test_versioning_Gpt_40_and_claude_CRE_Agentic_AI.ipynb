{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "IX7KhzaJbF8-"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "!pip install anthropic\n",
        "!pip install langgraph langchain langchain_core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tgmo4iqobHNJ"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "import os\n",
        "from anthropic import Anthropic\n",
        "from openai import OpenAI\n",
        "import re\n",
        "import traceback\n",
        "import io\n",
        "from contextlib import redirect_stdout\n",
        "import numpy as np\n",
        "import logging\n",
        "import json\n",
        "from typing import List, Optional, Dict, Any, Union\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langgraph.graph import StateGraph, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMymkJcBcBB5"
      },
      "outputs": [],
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger('rent_roll_analyzer')\n",
        "\n",
        "# Global variables and API keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Yes16m2AcCzI"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Optional, Union, Dict, Any\n",
        "\n",
        "# Define the state as a TypedDict\n",
        "class AgentState(TypedDict, total=False):\n",
        "    messages: List[Dict[str, str]]\n",
        "    df: Optional[pd.DataFrame]\n",
        "    issues: List[str]\n",
        "    execution_plan: Optional[str]\n",
        "    needs_clarification: bool\n",
        "    clarification_question: Optional[str]\n",
        "    generate_code: bool\n",
        "    code_execution_results: Optional[str]\n",
        "    final_response: Optional[str]\n",
        "    anthropic_client: Optional[Any]  # For Claude API\n",
        "    openai_client: Optional[Any]     # For OpenAI API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HlFG6YSrcEUU"
      },
      "outputs": [],
      "source": [
        "def read_rent_roll_simple(file_path):\n",
        "    \"\"\"\n",
        "    Improved function to read rent roll Excel files that handles special formatting\n",
        "    commonly found in commercial real estate rent roll sheets.\n",
        "    \"\"\"\n",
        "    # Read the raw Excel file with no header\n",
        "    df = pd.read_excel(file_path, header=None)\n",
        "\n",
        "    # Find the row containing the column headers\n",
        "    header_row = None\n",
        "    for i, row in df.iterrows():\n",
        "        if row.iloc[0] == \"Current\":\n",
        "            header_row = i + 1  # Headers are in the row after \"Current\"\n",
        "            break\n",
        "\n",
        "    if header_row is None:\n",
        "        logger.warning(\"Could not find header row with 'Current' marker. Falling back to standard loading.\")\n",
        "        return pd.read_excel(file_path)\n",
        "\n",
        "    # Get the headers\n",
        "    headers = []\n",
        "    for val in df.iloc[header_row]:\n",
        "        if pd.isna(val):\n",
        "            headers.append(\"NaN\")  # Use \"NaN\" for empty header cells\n",
        "        else:\n",
        "            headers.append(str(val))\n",
        "\n",
        "    # Create a new dataframe starting after the header row\n",
        "    data_rows = df.iloc[(header_row+1):].values\n",
        "\n",
        "    # Create a new dataframe with the extracted headers\n",
        "    result_df = pd.DataFrame(data_rows, columns=headers)\n",
        "\n",
        "    logger.info(f\"Successfully loaded rent roll with {len(result_df)} rows using specialized loader\")\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JwQXfnG3cGOW"
      },
      "outputs": [],
      "source": [
        "def analyze_rent_roll_gpt(file_path, api_key):\n",
        "    \"\"\"\n",
        "    Analyzes a CRE rent roll Excel file by sending the data rows to GPT-4.\n",
        "    \"\"\"\n",
        "    # Load the rent roll\n",
        "    try:\n",
        "        df = read_rent_roll_simple(file_path)\n",
        "        logger.info(\"File loaded successfully for GPT analysis.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading file: {e}\")\n",
        "        return []\n",
        "\n",
        "    # Initialize OpenAI client\n",
        "    client = OpenAI(api_key=api_key)\n",
        "\n",
        "    # Convert the DataFrame to CSV string format\n",
        "    csv_data = df.to_csv(index=False)\n",
        "    logger.info(f\"Converted DataFrame to CSV with {len(df)} rows and {len(df.columns)} columns\")\n",
        "\n",
        "    # Enhance the system prompt to focus on general rent roll issues\n",
        "    system_prompt = \"\"\"\n",
        "    You are a Commercial Real Estate rent roll expert specializing in identifying data quality, formatting, and consistency issues.\n",
        "\n",
        "    When analyzing any CRE rent roll, rigorously check for these common categories of issues:\n",
        "\n",
        "    1. DUPLICATE OR REDUNDANT ENTRIES: Look for any repeated charges, fees, or line items\n",
        "    2. INCONSISTENT TERMINOLOGY: Identify any unclear, non-standard, or ambiguous descriptions\n",
        "    3. DATE ANOMALIES: Flag any suspicious or illogical date patterns across move-in, lease start/end\n",
        "    4. RENT DISCREPANCIES: Identify deviations between market rent values and actual charged amounts\n",
        "    5. CALCULATION INCONSISTENCIES: Check if component charges properly sum to totals\n",
        "    6. EXCEL ARTIFACTS: Identify any visible formulas, function calls, or spreadsheet mechanics\n",
        "    7. FORMATTING IRREGULARITIES: Notice inconsistent data entry patterns or splitting of information\n",
        "    8. BALANCE ANOMALIES: Identify unusual balances, especially negative values\n",
        "    9. OCCUPANCY MISMATCHES: Look for occupied units with zero rent or vacant units with charges\n",
        "    10. UNIT IDENTIFICATION PATTERNS: Check for inconsistencies in unit numbering or identification\n",
        "\n",
        "    Be extremely thorough and specific in your analysis. Report ALL issues you find, regardless of how minor they may seem.\n",
        "    DO NOT return \"No issues detected\" unless you've comprehensively analyzed the data for each category above.\n",
        "    \"\"\"\n",
        "\n",
        "    # Use a simplified prompt focused on analyzing the raw CSV data\n",
        "    prompt = (\n",
        "        f\"Please analyze this Commercial Real Estate rent roll data in CSV format and identify ALL potential issues \"\n",
        "        f\"that could affect data quality, accuracy, or decision-making.\\n\\n{csv_data}\\n\\n\"\n",
        "\n",
        "        f\"Based on your expertise in CRE rent rolls, provide a numbered list of ALL issues you can identify, including but not limited to:\\n\\n\"\n",
        "\n",
        "        f\"- Any duplicate or redundant charges\\n\"\n",
        "        f\"- Unclear, non-standard, or inconsistent descriptions\\n\"\n",
        "        f\"- Suspicious or illogical date patterns\\n\"\n",
        "        f\"- Inconsistencies between market rent and actual rent values\\n\"\n",
        "        f\"- Calculation errors where components don't match totals\\n\"\n",
        "        f\"- Spreadsheet artifacts like visible formulas\\n\"\n",
        "        f\"- Inconsistent data entry patterns\\n\"\n",
        "        f\"- Unusual balance values\\n\"\n",
        "        f\"- Occupancy status mismatches\\n\"\n",
        "        f\"- Inconsistent unit numbering or identification\\n\\n\"\n",
        "\n",
        "        f\"IMPORTANT: For each issue found, please reference the specific unit(s) affected and explain why it's problematic. \"\n",
        "        f\"Be comprehensive - rent roll accuracy is critical for CRE investment and property management decisions.\"\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Sending request to GPT-4 for analysis...\")\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=2000,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        response_text = response.choices[0].message.content\n",
        "        logger.info(\"Received response from GPT-4.\")\n",
        "\n",
        "        # Simple parsing of the response - split by numbered items\n",
        "        lines = response_text.split('\\n')\n",
        "        issues = []\n",
        "        current_issue = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            # If it's a new numbered item\n",
        "            if line.strip() and line[0].isdigit() and '. ' in line[:5]:\n",
        "                # If we were building a previous issue, add it\n",
        "                if current_issue:\n",
        "                    issues.append(current_issue.strip())\n",
        "                current_issue = line.strip()\n",
        "            elif line.strip() and current_issue:\n",
        "                # Continue building the current issue\n",
        "                current_issue += \" \" + line.strip()\n",
        "\n",
        "        # Add the last issue if there is one\n",
        "        if current_issue:\n",
        "            issues.append(current_issue.strip())\n",
        "\n",
        "        if not issues:\n",
        "            issues.append(\"No issues detected by GPT-4.\")\n",
        "\n",
        "        logger.info(f\"Identified {len(issues)} issues in the rent roll\")\n",
        "        return issues\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calling GPT-4 for analysis: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "        return [\"Failed to analyze rent roll due to API error.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "05TftxjAcKhx"
      },
      "outputs": [],
      "source": [
        "def determine_action(state):\n",
        "    \"\"\"Decide whether to answer directly, ask for clarification, or generate code.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    user_message = messages[-1][\"content\"] if messages[-1][\"role\"] == \"user\" else \"\"\n",
        "    df = state[\"df\"]\n",
        "\n",
        "    # Create OpenAI client for this function call\n",
        "    client = OpenAI(api_key=DEFAULT_OPENAI_API_KEY)\n",
        "\n",
        "    # Get column information for context\n",
        "    if df is not None:\n",
        "        try:\n",
        "            # Safer way to get column data types\n",
        "            column_info = []\n",
        "            for col in df.columns:\n",
        "                try:\n",
        "                    dtype_str = str(df[col].dtype)  # Convert dtype to string directly\n",
        "                    column_info.append(f\"- {col}: {dtype_str}\")\n",
        "                except:\n",
        "                    column_info.append(f\"- {col}: unknown type\")\n",
        "            column_info_str = \"\\n\".join(column_info)\n",
        "            df_preview = df.head(3).to_string()\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting column info: {e}\")\n",
        "            column_info_str = \"Error retrieving column information\"\n",
        "            df_preview = \"Error retrieving data preview\"\n",
        "    else:\n",
        "        column_info_str = \"No dataframe loaded\"\n",
        "        df_preview = \"No data available\"\n",
        "\n",
        "    # Use GPT-4 to analyze the query and determine the best action\n",
        "    prompt = f\"\"\"\n",
        "    User query: {user_message}\n",
        "\n",
        "    Dataframe information:\n",
        "    - Rows: {len(df) if df is not None else 'No data loaded'}\n",
        "    - Columns: {column_info_str}\n",
        "\n",
        "    Data preview:\n",
        "    {df_preview}\n",
        "\n",
        "    Analyze the user query and determine the most appropriate action:\n",
        "    1. If the query is ambiguous or lacks specificity, choose \"ask_clarification\"\n",
        "    2. If the query can be answered with a simple explanation without analysis, choose \"text_response\"\n",
        "    3. If the query requires data analysis, calculations, or visualizations, choose \"generate_code\"\n",
        "\n",
        "    Respond with a JSON object containing:\n",
        "    {{\"action\": \"ask_clarification\" | \"text_response\" | \"generate_code\", \"reason\": \"brief explanation\"}}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a decision-making agent for a rent roll analysis system. Output ONLY a JSON object with the determined action and reason.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=500,\n",
        "            temperature=0.2\n",
        "        )\n",
        "\n",
        "        response_text = response.choices[0].message.content\n",
        "\n",
        "        # Extract JSON from the response\n",
        "        json_match = re.search(r'{.*}', response_text, re.DOTALL)\n",
        "        if json_match:\n",
        "            action_data = json.loads(json_match.group(0))\n",
        "            action = action_data.get(\"action\", \"text_response\")\n",
        "        else:\n",
        "            # Default to text response if parsing fails\n",
        "            action = \"text_response\"\n",
        "\n",
        "        logger.info(f\"Determined action using GPT-4: {action}\")\n",
        "\n",
        "        # Create a new state dict with updated values\n",
        "        new_state = dict(state)  # Create a copy\n",
        "        new_state[\"needs_clarification\"] = action == \"ask_clarification\"\n",
        "        new_state[\"generate_code\"] = action == \"generate_code\"\n",
        "\n",
        "        return new_state\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in determine_action: {e}\")\n",
        "        # Default to text response on error\n",
        "        new_state = dict(state)\n",
        "        new_state[\"needs_clarification\"] = False\n",
        "        new_state[\"generate_code\"] = False\n",
        "        return new_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_IDnMakrcOA4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ask_clarification(state: AgentState) -> Dict:\n",
        "    \"\"\"Generate a clarification question for the user using GPT-4.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    user_message = messages[-1][\"content\"] if messages[-1][\"role\"] == \"user\" else \"\"\n",
        "\n",
        "    # Create OpenAI client for this function call\n",
        "    client = OpenAI(api_key=DEFAULT_OPENAI_API_KEY)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"\"\"You are a commercial real estate rent roll analyst.\n",
        "                Generate a clear, specific clarification question to better understand\n",
        "                what the user is asking about their rent roll data.\"\"\"},\n",
        "                {\"role\": \"user\", \"content\": f\"My question is: {user_message}\"}\n",
        "            ],\n",
        "            max_tokens=300,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        clarification_question = response.choices[0].message.content\n",
        "\n",
        "        # Create a new state dict with updated values\n",
        "        new_state = dict(state)\n",
        "        new_state[\"clarification_question\"] = clarification_question\n",
        "        new_state[\"final_response\"] = clarification_question\n",
        "\n",
        "        # Add the clarification question to the messages\n",
        "        new_messages = state[\"messages\"].copy()\n",
        "        new_messages.append({\"role\": \"assistant\", \"content\": clarification_question})\n",
        "        new_state[\"messages\"] = new_messages\n",
        "\n",
        "        logger.info(f\"Generated clarification question using GPT-4: {clarification_question[:50]}...\")\n",
        "        return new_state\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in ask_clarification: {e}\")\n",
        "        # Fallback to a generic clarification question\n",
        "        generic_question = \"Could you please clarify what specific aspect of the rent roll you'd like me to analyze?\"\n",
        "\n",
        "        new_state = dict(state)\n",
        "        new_state[\"clarification_question\"] = generic_question\n",
        "        new_state[\"final_response\"] = generic_question\n",
        "\n",
        "        new_messages = state[\"messages\"].copy()\n",
        "        new_messages.append({\"role\": \"assistant\", \"content\": generic_question})\n",
        "        new_state[\"messages\"] = new_messages\n",
        "\n",
        "        return new_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "i-C3FXmrcQ8J"
      },
      "outputs": [],
      "source": [
        "def generate_text_response(state):\n",
        "    \"\"\"Generate a simple text response to the user query using GPT-4.\"\"\"\n",
        "\n",
        "    messages = state[\"messages\"]\n",
        "    df = state[\"df\"]\n",
        "    issues = state[\"issues\"]\n",
        "\n",
        "    # Create OpenAI client for this function call\n",
        "    client = OpenAI(api_key=DEFAULT_OPENAI_API_KEY)\n",
        "\n",
        "    # Prepare context for GPT-4\n",
        "    issues_text = \"\\n\".join([f\"- {issue}\" for issue in issues])\n",
        "\n",
        "    # Get column and data preview for context\n",
        "    if df is not None:\n",
        "        column_info = \", \".join(df.columns)\n",
        "        data_stats = []\n",
        "        for col in df.columns[:10]:  # Limit to first 10 columns to avoid token limits\n",
        "            try:\n",
        "                if pd.api.types.is_numeric_dtype(df[col]):\n",
        "                    stat = f\"- {col}: min={df[col].min()}, max={df[col].max()}, mean={df[col].mean():.2f}, null={df[col].isna().sum()}\"\n",
        "                else:\n",
        "                    unique_vals = df[col].nunique()\n",
        "                    stat = f\"- {col}: unique values={unique_vals}, null={df[col].isna().sum()}\"\n",
        "                data_stats.append(stat)\n",
        "            except:\n",
        "                data_stats.append(f\"- {col}: [error calculating stats]\")\n",
        "        data_stats_str = \"\\n\".join(data_stats)\n",
        "        df_preview = df.head(3).to_string()\n",
        "    else:\n",
        "        column_info = \"No columns available\"\n",
        "        data_stats_str = \"No data statistics available\"\n",
        "        df_preview = \"No data preview available\"\n",
        "\n",
        "    system_prompt = f\"\"\"You are a commercial real estate rent roll analyst.\n",
        "    The rent roll data has {len(df) if df is not None else 0} rows and\n",
        "    {len(df.columns) if df is not None else 0} columns.\n",
        "\n",
        "    Column information: {column_info}\n",
        "\n",
        "    Data statistics:\n",
        "    {data_stats_str}\n",
        "\n",
        "    Data preview:\n",
        "    {df_preview}\n",
        "\n",
        "    Identified issues:\n",
        "    {issues_text}\n",
        "\n",
        "    Provide a concise, informative answer to the user's question.\n",
        "    Focus on being helpful and direct, with only 1-2 paragraphs.\n",
        "    Do not include code or detailed analysis unless absolutely necessary.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract system message and filter other messages\n",
        "    filtered_messages = []\n",
        "    for msg in messages:\n",
        "        if msg[\"role\"] != \"system\":\n",
        "            filtered_messages.append(msg)\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                *filtered_messages\n",
        "            ],\n",
        "            max_tokens=1000,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        text_response = response.choices[0].message.content\n",
        "\n",
        "        # Create a new state dict with updated values\n",
        "        new_state = dict(state)\n",
        "        new_state[\"final_response\"] = text_response\n",
        "\n",
        "        # Add the response to the messages\n",
        "        new_messages = state[\"messages\"].copy()\n",
        "        new_messages.append({\"role\": \"assistant\", \"content\": text_response})\n",
        "        new_state[\"messages\"] = new_messages\n",
        "\n",
        "        logger.info(f\"Generated text response using GPT-4: {text_response[:50]}...\")\n",
        "        return new_state\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in generate_text_response: {e}\")\n",
        "        # Fallback to a generic response\n",
        "        fallback_response = \"I'm sorry, I'm having trouble analyzing your rent roll data right now. Could you try rephrasing your question?\"\n",
        "\n",
        "        new_state = dict(state)\n",
        "        new_state[\"final_response\"] = fallback_response\n",
        "\n",
        "        new_messages = state[\"messages\"].copy()\n",
        "        new_messages.append({\"role\": \"assistant\", \"content\": fallback_response})\n",
        "        new_state[\"messages\"] = new_messages\n",
        "\n",
        "        return new_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iiwl_X7iDPVC"
      },
      "outputs": [],
      "source": [
        "def trim_dataframe_output(output_text, max_rows=20, max_chars=None):\n",
        "    \"\"\"\n",
        "    Extremely simplified function that just returns the first 20 lines of output.\n",
        "\n",
        "    Args:\n",
        "        output_text: The text output\n",
        "        max_rows: Maximum number of rows to keep (default: 20)\n",
        "        max_chars: Not used, kept for compatibility\n",
        "\n",
        "    Returns:\n",
        "        Trimmed text showing only top rows\n",
        "    \"\"\"\n",
        "    lines = output_text.split('\\n')\n",
        "\n",
        "    if len(lines) <= max_rows:\n",
        "        return output_text\n",
        "\n",
        "    trimmed_lines = lines[:max_rows]\n",
        "    trimmed_lines.append(f\"... [output truncated, showing first {max_rows} lines only] ...\")\n",
        "\n",
        "    return '\\n'.join(trimmed_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EeQetycQblZd"
      },
      "outputs": [],
      "source": [
        "\n",
        "from datetime import datetime\n",
        "def save_dataframe_version(df, operation_description=\"\"):\n",
        "    \"\"\"Save the current state of the dataframe as both CSV and Excel files.\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe to save\n",
        "        operation_description: A string describing what operation was performed\n",
        "\n",
        "    Returns:\n",
        "        version_name: The name of the version that was saved\n",
        "    \"\"\"\n",
        "    import os\n",
        "    from datetime import datetime\n",
        "\n",
        "    # Create versions directory if it doesn't exist\n",
        "    versions_dir = \"rent_roll_versions\"\n",
        "    os.makedirs(versions_dir, exist_ok=True)\n",
        "\n",
        "    # Generate version name with timestamp\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    version_name = f\"v_{timestamp}\"\n",
        "\n",
        "    # Create filenames for both CSV and Excel\n",
        "    csv_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.csv\")\n",
        "    excel_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.xlsx\")\n",
        "\n",
        "    # Save as CSV\n",
        "    df.to_csv(csv_filename, index=False)\n",
        "\n",
        "    # Save as Excel\n",
        "    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
        "\n",
        "    # Add version metadata to the registry\n",
        "    if 'app_state' in globals():\n",
        "        version_info = {\n",
        "            'name': version_name,\n",
        "            'description': operation_description,\n",
        "            'timestamp': timestamp,\n",
        "            'filename': csv_filename,  # Keep CSV as primary for backward compatibility\n",
        "            'excel_filename': excel_filename,  # Add Excel filename\n",
        "            'is_original': len(app_state[\"df_versions\"]) == 0  # First one is original\n",
        "        }\n",
        "        app_state[\"df_versions\"].append(version_info)\n",
        "\n",
        "    print(f\"✓ Saved dataframe version {version_name}: {operation_description}\")\n",
        "    print(f\"  - CSV: {csv_filename}\")\n",
        "    print(f\"  - Excel: {excel_filename}\")\n",
        "\n",
        "    # Return the version name for reference\n",
        "    return version_name\n",
        "\n",
        "def get_versions_info_for_prompt():\n",
        "    \"\"\"Generate version information for the Claude prompt.\"\"\"\n",
        "    if not app_state[\"df_versions\"]:\n",
        "        return \"No versions available yet.\"\n",
        "\n",
        "    # Find the original version\n",
        "    original = next((v for v in app_state[\"df_versions\"] if v.get('is_original')), app_state[\"df_versions\"][0])\n",
        "\n",
        "    # Get the latest version\n",
        "    latest = app_state[\"df_versions\"][-1]\n",
        "\n",
        "    # Format all versions\n",
        "    all_versions = []\n",
        "    for i, version in enumerate(app_state[\"df_versions\"]):\n",
        "        status = []\n",
        "        if version == original:\n",
        "            status.append(\"ORIGINAL\")\n",
        "        if version == latest:\n",
        "            status.append(\"LATEST\")\n",
        "\n",
        "        status_str = f\" ({', '.join(status)})\" if status else \"\"\n",
        "        all_versions.append(f\"{i+1}. {version['name']}{status_str}: {version['description']}\")\n",
        "\n",
        "    versions_text = \"\\n\".join(all_versions)\n",
        "\n",
        "    return f\"\"\"\n",
        "DATAFRAME VERSION HISTORY:\n",
        "{versions_text}\n",
        "\n",
        "Original version: {original['name']}\n",
        "Latest version: {latest['name']}\n",
        "Total versions: {len(app_state[\"df_versions\"])}\n",
        "\"\"\"\n",
        "\n",
        "def generate_code_and_execute(state: AgentState) -> Dict:\n",
        "    \"\"\"\n",
        "    Generate and execute code using a two-step AI approach:\n",
        "    1. Use GPT-4 to create an optimal prompt for Claude\n",
        "    2. Have Claude generate the code based on this optimized prompt\n",
        "    3. Execute the code and handle errors with up to 3 retries\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "    df = state[\"df\"]\n",
        "\n",
        "    # Get OpenAI client from state or create new one\n",
        "    openai_client = state.get(\"openai_client\") or OpenAI(api_key=DEFAULT_OPENAI_API_KEY)\n",
        "    # Get Anthropic client from state or create new one\n",
        "    anthropic_client = state.get(\"anthropic_client\") or Anthropic(api_key=DEFAULT_ANTHROPIC_API_KEY)\n",
        "\n",
        "    # Get column information for context\n",
        "    column_info = \", \".join(df.columns) if df is not None else \"No columns available\"\n",
        "\n",
        "    # Create a snapshot of the dataframe to show Claude\n",
        "    df_sample = df.head(10).to_string() if df is not None else \"No data available\"\n",
        "\n",
        "    # Create versions directory if it doesn't exist\n",
        "    versions_dir = \"rent_roll_versions\"\n",
        "    os.makedirs(versions_dir, exist_ok=True)\n",
        "\n",
        "    # Print initial state for debugging\n",
        "    print(f\"\\n==== STARTING CODE GENERATION ====\")\n",
        "    print(f\"User query: {messages[-1]['content'] if messages[-1]['role'] == 'user' else 'No user query found'}\")\n",
        "    print(f\"Dataframe has {len(df) if df is not None else 0} rows and {len(df.columns) if df is not None else 0} columns\")\n",
        "\n",
        "    try:\n",
        "        # First, use GPT-4 to create the optimal prompt for Claude\n",
        "        print(\"\\n==== STEP 1: GENERATING PROMPT WITH GPT-4 ====\")\n",
        "        versions_info = get_versions_info_for_prompt()\n",
        "        # System prompt for GPT-4 to create a Claude prompt\n",
        "        gpt_system_prompt = f\"\"\"You are an expert at creating prompts for Claude AI to generate code.\n",
        "        Your task is to analyze the user query history and convert it into an optimal prompt for Claude to generate Python code that analyzes a rent roll dataframe.\n",
        "\n",
        "        CRITICAL INFORMATION: The dataframe is ALREADY LOADED and available as 'df'.\n",
        "        It contains REAL DATA with {len(df)} rows and {len(df.columns)} columns.\n",
        "\n",
        "        Here is a sample of the actual data (first 5 rows):\n",
        "        {df_sample}\n",
        "\n",
        "        The dataframe has the following columns: {column_info}\n",
        "\n",
        "        # IMPORTANT: DATAFRAME VERSION MANAGEMENT\n",
        "        {versions_info}\n",
        "\n",
        "        # IMPORTANT VERSION IDENTIFICATION:\n",
        "        - Versions are stored in chronological order by timestamp\n",
        "        - The original version is always the first one saved (earliest timestamp)\n",
        "        - The latest version is always the most recent one saved (latest timestamp)\n",
        "        - When a user says \"original dataframe,\" load the version with the earliest timestamp\n",
        "        - When a user says \"latest version,\" use the current df (which is already the latest)\n",
        "        - When a user specifies a version by name (e.g., \"v_20250518_112345\"), load that exact version\n",
        "\n",
        "        ALL versions are saved as CSV files in the \"rent_roll_versions\" directory.\n",
        "        For example, to load a specific version:\n",
        "\n",
        "        ```python\n",
        "        # To load a specific version (e.g., the original version)\n",
        "        import pandas as pd\n",
        "        import os\n",
        "\n",
        "        # Example: Load the original version\n",
        "        original_version_name = \"{{app_state[\"df_versions\"][0]['name'] if app_state[\"df_versions\"] else \"v_example\"}}\"\n",
        "        original_file_path = os.path.join(\"rent_roll_versions\", f\"rent_roll_{{original_version_name}}.csv\")\n",
        "        original_df = pd.read_csv(original_file_path)\n",
        "\n",
        "        print(f\"Loaded original version: {{original_version_name}}\")\n",
        "        print(f\"Shape: {{original_df.shape}}\")\n",
        "\n",
        "        # You can either work with this as a separate dataframe, or replace the current df:\n",
        "        # df = original_df  # This would replace the current df with the original\n",
        "        ```\n",
        "\n",
        "        If you make any changes to the dataframe, ALWAYS save a new version using save_dataframe_version().\n",
        "\n",
        "        Some important guidelines to include in your prompt to Claude:\n",
        "        1. The variable 'df' is ALREADY DEFINED and CONTAINS DATA. Claude must not say \"I need to see the data first\"\n",
        "        2. Claude should explain its approach step by step before showing code\n",
        "        3. Code must be wrapped in ```python and ``` blocks\n",
        "        4. Code MUST display ALL rows in the output when showing tables (no limiting rows)\n",
        "        5. Claude should not attempt to clean data unless specifically requested\n",
        "        6. Code should include proper error handling\n",
        "        7. IMPORTANT: After performing any analysis or showing results, Claude should ALWAYS call the save_dataframe_version() function to maintain version history, even if no changes were made to the dataframe.\n",
        "        8. CRITICAL: Claude should NOT use try-except blocks in its code. Any errors should be allowed to propagate naturally. This ensures that our retry system can properly handle errors.\n",
        "\n",
        "        Your output will be directly sent to Claude, so format it as a complete system prompt.\n",
        "        Include any table formatting functions that might be useful.\n",
        "\n",
        "        Make sure to include these helper functions in your prompt:\n",
        "\n",
        "        ```python\n",
        "        # For tabular display with proper formatting (PREFERRED METHOD):\n",
        "        def print_formatted_table(df, title=None): #Print a dataframe with proper formatting without modifying data\n",
        "            if title:\n",
        "                print(f\"\\\\n{{title}}\")\n",
        "                print(\"=\" * 80)\n",
        "\n",
        "            # Create a display copy (doesn't change original df)\n",
        "            display_df = df.copy()\n",
        "\n",
        "            # Set pandas display options for better readability\n",
        "            # Show ALL rows - no limits\n",
        "            pd.set_option('display.max_rows', None)\n",
        "            pd.set_option('display.max_columns', None)\n",
        "            pd.set_option('display.width', 1000)\n",
        "            pd.set_option('display.colheader_justify', 'left')\n",
        "            pd.set_option('display.precision', 2)\n",
        "\n",
        "            # Display the dataframe - ALL rows will be shown\n",
        "            print(display_df)\n",
        "\n",
        "            # Reset display options to default\n",
        "            pd.reset_option('display.max_rows')\n",
        "            pd.reset_option('display.max_columns')\n",
        "            pd.reset_option('display.width')\n",
        "            pd.reset_option('display.colheader_justify')\n",
        "            pd.reset_option('display.precision')\n",
        "        ```\n",
        "\n",
        "        ```python\n",
        "        # For bordered table display with precise control:\n",
        "        def print_bordered_table(df, title=None): #Print a dataframe with borders for better readability - SHOWS ALL ROWS\n",
        "            if title:\n",
        "                print(f\"\\\\n{{title}}\")\n",
        "                print(\"=\" * 80)\n",
        "\n",
        "            if len(df) == 0:\n",
        "                print(\"No data available\")\n",
        "                return\n",
        "\n",
        "            # Create a display copy (doesn't change original data)\n",
        "            display_df = df.copy()\n",
        "\n",
        "            # Calculate column widths for display purposes only\n",
        "            col_widths = {{}}\n",
        "            for col in display_df.columns:\n",
        "                # Convert values to string only for width calculation\n",
        "                col_values = display_df[col].astype(str)\n",
        "                max_data_width = col_values.str.len().max()\n",
        "                col_widths[col] = max(len(str(col)), max_data_width) + 2  # +2 for padding\n",
        "\n",
        "            # Create header row\n",
        "            header = \"| \" + \" | \".join(str(col).ljust(col_widths[col]) for col in display_df.columns) + \" |\"\n",
        "            separator = \"+\" + \"+\".join(\"-\" * (col_widths[col] + 2) for col in display_df.columns) + \"+\"\n",
        "\n",
        "            # Print header\n",
        "            print(separator)\n",
        "            print(header)\n",
        "            print(separator)\n",
        "\n",
        "            # Print ALL rows - NO LIMIT\n",
        "            for i in range(len(display_df)):\n",
        "                row = display_df.iloc[i]\n",
        "                row_str = \"| \" + \" | \".join(str(val).ljust(col_widths[col]) for col, val in row.items()) + \" |\"\n",
        "                print(row_str)\n",
        "\n",
        "            print(separator)\n",
        "            print(f\"Total rows: {{len(display_df)}}\")\n",
        "        ```\n",
        "\n",
        "        ```python\n",
        "        # Function to save dataframe versions\n",
        "        def save_dataframe_version(df, operation_description=\"\"):\n",
        "            \\\"\\\"\\\"Save the current state of the dataframe as both CSV and Excel files.\n",
        "\n",
        "            This function should be called whenever you make changes to the dataframe,\n",
        "            or after generating analysis results, to maintain version history.\n",
        "\n",
        "            Args:\n",
        "                df: The dataframe to save\n",
        "                operation_description: A string describing what operation was performed\n",
        "\n",
        "            Returns:\n",
        "                version_name: The name of the version that was saved\n",
        "            \\\"\\\"\\\"\n",
        "            import os\n",
        "            from datetime import datetime\n",
        "\n",
        "            # Create versions directory if it doesn't exist\n",
        "            versions_dir = \"rent_roll_versions\"\n",
        "            os.makedirs(versions_dir, exist_ok=True)\n",
        "\n",
        "            # Generate version name with timestamp\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            version_name = f\"v_{{timestamp}}\"\n",
        "\n",
        "            # Create filenames for both CSV and Excel\n",
        "            csv_filename = os.path.join(versions_dir, f\"rent_roll_{{version_name}}.csv\")\n",
        "            excel_filename = os.path.join(versions_dir, f\"rent_roll_{{version_name}}.xlsx\")\n",
        "\n",
        "            # Save as CSV\n",
        "            df.to_csv(csv_filename, index=False)\n",
        "\n",
        "            # Save as Excel\n",
        "            df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
        "\n",
        "            print(f\"✓ Saved dataframe version {{version_name}}: {{operation_description}}\")\n",
        "            print(f\"  - CSV: {{csv_filename}}\")\n",
        "            print(f\"  - Excel: {{excel_filename}}\")\n",
        "\n",
        "            # Return the version name for reference\n",
        "            return version_name\n",
        "        ```\n",
        "        \"\"\"\n",
        "        # Filter out system messages and DON'T trim dataframe outputs in the conversation history\n",
        "        filtered_messages = []\n",
        "        for msg in messages:\n",
        "            if msg[\"role\"] != \"system\":\n",
        "                # Don't trim here anymore\n",
        "                filtered_messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
        "\n",
        "        # Convert the messages to the format expected by OpenAI\n",
        "        gpt_messages = [{\"role\": \"system\", \"content\": gpt_system_prompt}]\n",
        "        for msg in filtered_messages:\n",
        "            gpt_messages.append(msg)\n",
        "\n",
        "        # Add a final message explaining the task clearly\n",
        "        gpt_messages.append({\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Based on this conversation history, create the optimal Claude prompt to generate Python code for rent roll analysis. The prompt should emphasize that the dataframe already exists and is loaded as 'df', that ALL rows should be displayed when requested, and that versions should be saved with save_dataframe_version() function.\"\n",
        "        })\n",
        "\n",
        "        # Get the optimized prompt from GPT-4\n",
        "        gpt_response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4.1\",\n",
        "            messages=gpt_messages,\n",
        "            max_tokens=3000,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        claude_system_prompt = gpt_response.choices[0].message.content\n",
        "\n",
        "        # Print the generated prompt for debugging\n",
        "        print(\"\\n==== GPT-4 GENERATED PROMPT FOR CLAUDE ====\")\n",
        "        print(claude_system_prompt[:500] + \"...\" if len(claude_system_prompt) > 500 else claude_system_prompt)\n",
        "        print(\"==== END OF PROMPT (TRUNCATED) ====\\n\")\n",
        "\n",
        "        logger.info(\"Generated optimized prompt for Claude using GPT-4\")\n",
        "\n",
        "        # Now use the GPT-4 generated prompt to ask Claude for code\n",
        "        print(\"\\n==== STEP 2: SENDING TO CLAUDE FOR CODE GENERATION ====\")\n",
        "        logger.info(\"Sending optimized prompt to Claude for code generation\")\n",
        "\n",
        "        # Prepare messages for Claude with a dataframe sample\n",
        "        claude_messages = filtered_messages.copy()\n",
        "\n",
        "        # Add a sample of the actual dataframe to help Claude understand the data exists\n",
        "        sample_message = {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Here is a sample of the dataframe that's already loaded as 'df':\\n{df_sample}\\n\\nPlease process my request using this data and remember to save versions with save_dataframe_version().\"\n",
        "        }\n",
        "        claude_messages.append(sample_message)\n",
        "\n",
        "        # Try to get code from Claude\n",
        "        claude_response = anthropic_client.messages.create(\n",
        "            model=\"claude-3-7-sonnet-20250219\",\n",
        "            system=claude_system_prompt,\n",
        "            messages=claude_messages,\n",
        "            max_tokens=3500,\n",
        "            temperature=0.3\n",
        "        )\n",
        "\n",
        "        # Extract the response text from Claude\n",
        "        response_text = claude_response.content[0].text\n",
        "\n",
        "        # Print Claude's response for debugging\n",
        "        print(\"\\n==== CLAUDE'S RESPONSE ====\")\n",
        "        print(response_text[:500] + \"...\" if len(response_text) > 500 else response_text)\n",
        "        print(\"==== END OF CLAUDE RESPONSE (TRUNCATED) ====\\n\")\n",
        "\n",
        "        # Extract code blocks\n",
        "        code_blocks = re.findall(r'```python\\s*(.*?)\\s*```', response_text, re.DOTALL)\n",
        "\n",
        "        # Print extracted code blocks for debugging\n",
        "        print(f\"\\n==== EXTRACTED {len(code_blocks)} CODE BLOCKS ====\")\n",
        "        for i, block in enumerate(code_blocks):\n",
        "            print(f\"\\n-- Code Block {i+1} --\")\n",
        "            print(block[:200] + \"...\" if len(block) > 200 else block)\n",
        "\n",
        "        # If no code blocks are found, add emergency code\n",
        "        if len(code_blocks) == 0:\n",
        "            emergency_code = \"\"\"\n",
        "            # Emergency code to display the dataframe\n",
        "            pd.set_option('display.max_rows', None)\n",
        "            pd.set_option('display.max_columns', None)\n",
        "            pd.set_option('display.width', 1000)\n",
        "\n",
        "            print(\"\\\\n=== RENT ROLL DATA ===\\\\n\")\n",
        "            print(f\"Displaying all {len(df)} rows and {len(df.columns)} columns\\\\n\")\n",
        "\n",
        "            # Print the entire dataframe\n",
        "            print(df)\n",
        "\n",
        "            # Save a version of the dataframe\n",
        "            from datetime import datetime\n",
        "            import os\n",
        "\n",
        "            # Create versions directory if it doesn't exist\n",
        "            versions_dir = \"rent_roll_versions\"\n",
        "            os.makedirs(versions_dir, exist_ok=True)\n",
        "\n",
        "            # Generate version name with timestamp\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            version_name = f\"v_{timestamp}\"\n",
        "\n",
        "            # Create filename\n",
        "            filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.csv\")\n",
        "\n",
        "            # Save dataframe\n",
        "            df.to_csv(filename, index=False)\n",
        "\n",
        "            print(f\"✓ Saved dataframe version {version_name}: Emergency display of data\")\n",
        "            \"\"\"\n",
        "            code_blocks.append(emergency_code)\n",
        "            print(\"\\n-- Added Emergency Code Block --\")\n",
        "            print(\"Emergency code added since Claude didn't generate code\")\n",
        "\n",
        "        # Define helper functions\n",
        "        def print_formatted_table(df, title=None):\n",
        "            if title:\n",
        "                print(f\"\\n{title}\")\n",
        "                print(\"=\" * 80)\n",
        "\n",
        "            # Create a display copy (doesn't change original df)\n",
        "            display_df = df.copy()\n",
        "\n",
        "            # Set pandas display options for better readability\n",
        "            # Show ALL rows - no limits\n",
        "            pd.set_option('display.max_rows', None)\n",
        "            pd.set_option('display.max_columns', None)\n",
        "            pd.set_option('display.width', 1000)\n",
        "            pd.set_option('display.colheader_justify', 'left')\n",
        "            pd.set_option('display.precision', 2)\n",
        "\n",
        "            # Display the dataframe - ALL rows will be shown\n",
        "            print(display_df)\n",
        "\n",
        "            # Reset display options to default\n",
        "            pd.reset_option('display.max_rows')\n",
        "            pd.reset_option('display.max_columns')\n",
        "            pd.reset_option('display.width')\n",
        "            pd.reset_option('display.colheader_justify')\n",
        "            pd.reset_option('display.precision')\n",
        "\n",
        "        def print_bordered_table(df, title=None):\n",
        "            if title:\n",
        "                print(f\"\\n{title}\")\n",
        "                print(\"=\" * 80)\n",
        "\n",
        "            if len(df) == 0:\n",
        "                print(\"No data available\")\n",
        "                return\n",
        "\n",
        "            # Create a display copy (doesn't change original data)\n",
        "            display_df = df.copy()\n",
        "\n",
        "            # Calculate column widths for display purposes only\n",
        "            col_widths = {}\n",
        "            for col in display_df.columns:\n",
        "                # Convert values to string only for width calculation\n",
        "                col_values = display_df[col].astype(str)\n",
        "                max_data_width = col_values.str.len().max()\n",
        "                col_widths[col] = max(len(str(col)), max_data_width) + 2  # +2 for padding\n",
        "\n",
        "            # Create header row\n",
        "            header = \"| \" + \" | \".join(str(col).ljust(col_widths[col]) for col in display_df.columns) + \" |\"\n",
        "            separator = \"+\" + \"+\".join(\"-\" * (col_widths[col] + 2) for col in display_df.columns) + \"+\"\n",
        "\n",
        "            # Print header\n",
        "            print(separator)\n",
        "            print(header)\n",
        "            print(separator)\n",
        "\n",
        "            # Print ALL rows - NO LIMIT\n",
        "            for i in range(len(display_df)):\n",
        "                row = display_df.iloc[i]\n",
        "                row_str = \"| \" + \" | \".join(str(val).ljust(col_widths[col]) for col, val in row.items()) + \" |\"\n",
        "                print(row_str)\n",
        "\n",
        "            print(separator)\n",
        "            print(f\"Total rows: {len(display_df)}\")\n",
        "\n",
        "        # Add to globals_dict before executing code\n",
        "        globals_dict = {\n",
        "            \"df\": df,\n",
        "            \"pd\": pd,\n",
        "            \"np\": np,\n",
        "            \"os\": os,                   # Add os for folder creation\n",
        "            \"datetime\": datetime,       # Add datetime for timestamp\n",
        "            \"versions_dir\": versions_dir,  # Pass the versions directory\n",
        "            \"print_formatted_table\": print_formatted_table,  # Add the helper function\n",
        "            \"print_bordered_table\": print_bordered_table,    # Add the helper function\n",
        "            \"save_dataframe_version\": save_dataframe_version  # Make sure this is defined too\n",
        "        }\n",
        "\n",
        "        execution_results = \"\"\n",
        "        all_executed_successfully = False\n",
        "        max_retries = 5  # Maximum number of retries\n",
        "        retry_count = 0  # Initialize retry counter\n",
        "        failed_code = \"\"  # Store the failed code for context\n",
        "        error_msg = \"\"    # Store the error message\n",
        "\n",
        "        print(\"\\n==== STEP 3: EXECUTING CODE WITH RETRIES ====\")\n",
        "\n",
        "        # Main retry loop\n",
        "        while not all_executed_successfully and retry_count <= max_retries:\n",
        "            # If this is a retry attempt (not the first try)\n",
        "            if retry_count > 0:\n",
        "                print(f\"\\n==== RETRY ATTEMPT {retry_count}/{max_retries} ====\")\n",
        "\n",
        "                # Create a retry message with more details each time\n",
        "                retry_message = {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"\"\"The code you provided failed with this error: {error_msg}\n",
        "\n",
        "                    Here is the code that failed:\n",
        "                    ```python\n",
        "                    {failed_code}\n",
        "                    ```\n",
        "\n",
        "                    This is retry attempt {retry_count} of {max_retries}.\n",
        "\n",
        "                    {\"After multiple attempts, please try a completely different approach.\" if retry_count >= 2 else \"Please fix this specific error.\"}\n",
        "                    IMPORTANT: DO NOT use try-except blocks in your code. Allow any errors to propagate naturally so our system can detect them.\n",
        "                    Please fix this code to handle the specific error while maintaining the requirement to show ALL rows in the output and saving a version with save_dataframe_version().\n",
        "                    Return the corrected code wrapped in ```python and ``` blocks.\"\"\"\n",
        "                }\n",
        "\n",
        "                # Add this feedback to the messages\n",
        "                fix_messages = claude_messages.copy()\n",
        "                fix_messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "                fix_messages.append(retry_message)\n",
        "\n",
        "                # Get Claude's fixed code\n",
        "                retry_response = anthropic_client.messages.create(\n",
        "                    model=\"claude-3-7-sonnet-20250219\",\n",
        "                    system=claude_system_prompt,\n",
        "                    messages=fix_messages,\n",
        "                    max_tokens=3500,\n",
        "                    temperature=0.3\n",
        "                )\n",
        "\n",
        "                retry_text = retry_response.content[0].text\n",
        "                print(f\"\\n==== CLAUDE'S FIX SUGGESTION (ATTEMPT {retry_count}) ====\")\n",
        "                print(retry_text[:500] + \"...\" if len(retry_text) > 500 else retry_text)\n",
        "\n",
        "                # Extract the fixed code blocks\n",
        "                fixed_code_blocks = re.findall(r'```python\\s*(.*?)\\s*```', retry_text, re.DOTALL)\n",
        "\n",
        "                if fixed_code_blocks:\n",
        "                    # Use the first fixed code block\n",
        "                    code_to_execute = fixed_code_blocks[0]\n",
        "\n",
        "                    # Update response text to include the fix explanation\n",
        "                    fix_explanation = f\"\\n\\n**🔧 Code Fix (Attempt {retry_count}):**\\n\"\n",
        "                    fix_explanation += f\"The code encountered an error. Here's the fix for retry attempt {retry_count}:\\n\"\n",
        "                    fix_explanation += \"\\n```python\\n\" + code_to_execute + \"\\n```\\n\"\n",
        "\n",
        "                    if retry_count == 1:\n",
        "                        # First retry - add to original response\n",
        "                        response_text = response_text + fix_explanation\n",
        "                    else:\n",
        "                        # Subsequent retries - replace previous fix explanation\n",
        "                        prev_fix_marker = f\"**🔧 Code Fix (Attempt {retry_count-1}):**\"\n",
        "                        if prev_fix_marker in response_text:\n",
        "                            # Replace previous fix with new one\n",
        "                            response_text = response_text.replace(\n",
        "                                prev_fix_marker,\n",
        "                                f\"**🔧 Code Fix (Attempt {retry_count}):**\"\n",
        "                            )\n",
        "                        else:\n",
        "                            # Just append this fix\n",
        "                            response_text = response_text + fix_explanation\n",
        "                else:\n",
        "                    # If no code blocks found in retry, try emergency code\n",
        "                    code_to_execute = f\"\"\"\n",
        "                    # Emergency code for retry {retry_count}\n",
        "                    print(f\"\\\\n=== EMERGENCY DISPLAY (RETRY {retry_count}) ===\\\\n\")\n",
        "                    print(f\"DataFrame shape: {{df.shape}}\")\n",
        "                    print(\"\\\\nColumn names:\")\n",
        "                    for col in df.columns:\n",
        "                        print(f\"- {{col}}\")\n",
        "\n",
        "                    print(\"\\\\nFirst 10 rows:\")\n",
        "                    print(df.head(10))\n",
        "\n",
        "                    save_dataframe_version(df, f\"Emergency display after retry {retry_count}\")\n",
        "                    \"\"\"\n",
        "                    print(f\"No code blocks found in retry. Using emergency code.\")\n",
        "            else:\n",
        "                # Initial execution (not a retry)\n",
        "                # Run the original code block\n",
        "                if code_blocks:\n",
        "                    code_to_execute = code_blocks[0]  # Use the first code block\n",
        "                else:\n",
        "                    # This should not happen due to the earlier check, but just in case\n",
        "                    code_to_execute = \"\"\"\n",
        "                    print(\"No code blocks found. Displaying basic dataframe info.\")\n",
        "                    print(f\"DataFrame shape: {df.shape}\")\n",
        "                    print(df.head())\n",
        "                    save_dataframe_version(df, \"Automatic save after initial execution\")\n",
        "                    \"\"\"\n",
        "\n",
        "            # Execute the current code\n",
        "            print(f\"\\n{'Executing' if retry_count == 0 else 'Retrying'} code...\")\n",
        "            output_buffer = io.StringIO()\n",
        "            try:\n",
        "                # Store the code in case it fails\n",
        "                failed_code = code_to_execute\n",
        "\n",
        "                with redirect_stdout(output_buffer):\n",
        "                    exec(code_to_execute, globals_dict)\n",
        "\n",
        "                execution_output = output_buffer.getvalue()\n",
        "                print(f\"Execution {'successful' if retry_count == 0 else 'fixed on retry ' + str(retry_count)}! Output length: {len(execution_output)} characters\")\n",
        "                print(execution_output[:200] + \"...\" if len(execution_output) > 200 else execution_output)\n",
        "\n",
        "                # ONLY trim the execution output for storing, not the entire response\n",
        "                trimmed_output = trim_dataframe_output(execution_output, max_rows=20)\n",
        "\n",
        "                # Format the results message based on retry count\n",
        "                if retry_count == 0:\n",
        "                    results_msg = \"**✅ Code Execution Results:**\"\n",
        "                else:\n",
        "                    results_msg = f\"**✅ Code Execution Results (After Fix Attempt {retry_count}):**\"\n",
        "\n",
        "                execution_results = f\"\\n\\n{results_msg}\\n```\\n{trimmed_output}\\n```\\n\"\n",
        "\n",
        "                # Check if a version was saved\n",
        "                if \"✓ Saved dataframe version\" not in execution_output:\n",
        "                    # Auto-save a version\n",
        "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                    version_name = f\"v_{timestamp}\"\n",
        "                    csv_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.csv\")\n",
        "                    excel_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.xlsx\")\n",
        "\n",
        "                    # Save both CSV and Excel\n",
        "                    df.to_csv(csv_filename, index=False)\n",
        "                    df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
        "\n",
        "                    save_message = f\"✓ Saved dataframe version {version_name}: Automatic save after {'execution' if retry_count == 0 else 'retry ' + str(retry_count)}\"\n",
        "                    print(save_message)\n",
        "                    print(f\"  - CSV: {csv_filename}\")\n",
        "                    print(f\"  - Excel: {excel_filename}\")\n",
        "                    execution_results += f\"\\n{save_message}\\n\"\n",
        "\n",
        "                # Mark as successful and break the retry loop\n",
        "                all_executed_successfully = True\n",
        "                logger.info(f\"Successfully executed code {'' if retry_count == 0 else 'on retry ' + str(retry_count)}\")\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                # Execution failed\n",
        "                error_msg = f\"Error: {str(e)}\"\n",
        "                print(f\"Execution failed with error: {error_msg}\")\n",
        "\n",
        "                # Log the error\n",
        "                if retry_count == 0:\n",
        "                    execution_results = f\"\\n\\n**❌ Code Execution Failed:**\\n```\\n{error_msg}\\n```\\n\"\n",
        "                else:\n",
        "                    execution_results = f\"\\n\\n**❌ Code Execution Failed (Retry {retry_count}):**\\n```\\n{error_msg}\\n```\\n\"\n",
        "\n",
        "                logger.error(f\"Code execution failed on {'initial attempt' if retry_count == 0 else 'retry ' + str(retry_count)}: {e}\")\n",
        "                logger.error(traceback.format_exc())\n",
        "\n",
        "                # Increment retry counter\n",
        "                retry_count += 1\n",
        "\n",
        "                # If we've hit max retries and still failed, try emergency display as last resort\n",
        "                if retry_count > max_retries:\n",
        "                    print(\"\\n==== MAX RETRIES REACHED, TRYING EMERGENCY DISPLAY ====\")\n",
        "\n",
        "                    # Create emergency display code\n",
        "                    emergency_code = \"\"\"\n",
        "                    try:\n",
        "                        print(\"\\\\n=== EMERGENCY FALLBACK DISPLAY ===\\\\n\")\n",
        "                        print(f\"DataFrame shape: {df.shape}\")\n",
        "                        print(\"\\\\nColumn names:\")\n",
        "                        for col in df.columns:\n",
        "                            print(f\"- {col}\")\n",
        "\n",
        "                        print(\"\\\\nFirst 10 rows:\")\n",
        "                        print(df.head(10))\n",
        "\n",
        "                        # Try to show some basic stats about numeric columns\n",
        "                        try:\n",
        "                            numeric_cols = df.select_dtypes(include=['number']).columns\n",
        "                            if len(numeric_cols) > 0:\n",
        "                                print(\"\\\\nBasic statistics for numeric columns:\")\n",
        "                                print(df[numeric_cols].describe())\n",
        "                        except Exception as stats_err:\n",
        "                            print(f\"Could not generate statistics: {stats_err}\")\n",
        "\n",
        "                        # Save version - both CSV and Excel\n",
        "                        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "                        version_name = f\"v_{timestamp}_emergency\"\n",
        "                        csv_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.csv\")\n",
        "                        excel_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.xlsx\")\n",
        "\n",
        "                        df.to_csv(csv_filename, index=False)\n",
        "                        df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
        "\n",
        "                        print(f\"✓ Saved dataframe version {version_name}: Emergency display after all retries failed\")\n",
        "                        print(f\"  - CSV: {csv_filename}\")\n",
        "                        print(f\"  - Excel: {excel_filename}\")\n",
        "                    except Exception as e_inner:\n",
        "                        print(f\"Even emergency display failed: {e_inner}\")\n",
        "                    \"\"\"\n",
        "\n",
        "\n",
        "                    output_buffer = io.StringIO()\n",
        "                    try:\n",
        "                        with redirect_stdout(output_buffer):\n",
        "                            exec(emergency_code, globals_dict)\n",
        "\n",
        "                        emergency_output = output_buffer.getvalue()\n",
        "                        # Only trim the emergency output, not the whole response\n",
        "                        execution_results += f\"\\n\\n**⚠️ Emergency Data Display (After {max_retries} Failed Retries):**\\n```\\n{trim_dataframe_output(emergency_output, max_rows=20)}\\n```\\n\"\n",
        "                    except Exception as e_final:\n",
        "                        print(f\"Emergency fallback also failed: {e_final}\")\n",
        "                        execution_results += f\"\\n\\n**❌ All Recovery Attempts Failed**\\n\"\n",
        "\n",
        "        # Add a note about the hybrid approach and retry attempts\n",
        "        if retry_count > 0 and all_executed_successfully:\n",
        "            hybrid_note = f\"\\n\\n**📝 Note:** This analysis was performed using a hybrid approach with GPT-4 and Claude. The code was successfully fixed after {retry_count} retry attempts.\"\n",
        "        elif retry_count > max_retries:\n",
        "            hybrid_note = f\"\\n\\n**📝 Note:** This analysis was attempted using a hybrid approach with GPT-4 and Claude, but all {max_retries} retry attempts failed. Some basic information was displayed as a fallback.\"\n",
        "        else:\n",
        "            hybrid_note = \"\\n\\n**📝 Note:** This analysis was performed using a hybrid approach: GPT-4 optimized the prompt, and Claude generated and executed the code for detailed rent roll analysis.\"\n",
        "\n",
        "        # Combine the response and execution results\n",
        "        full_response = response_text + execution_results + hybrid_note\n",
        "\n",
        "        print(\"\\n==== FINAL RESPONSE GENERATED ====\")\n",
        "        print(f\"Original response length: {len(full_response)} characters\")\n",
        "        print(f\"Retry attempts: {retry_count}\")\n",
        "        print(f\"Execution successful: {all_executed_successfully}\")\n",
        "\n",
        "        # Create a new state dict with updated values\n",
        "        new_state = dict(state)\n",
        "        new_state[\"code_execution_results\"] = execution_results\n",
        "        new_state[\"final_response\"] = full_response  # Don't trim the full response\n",
        "\n",
        "        # Add the response to the messages - don't trim it here either\n",
        "        new_messages = state[\"messages\"].copy()\n",
        "        new_messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
        "        new_state[\"messages\"] = new_messages\n",
        "\n",
        "        logger.info(\"Code generation and execution complete using hybrid GPT-4/Claude approach\")\n",
        "        print(\"\\n==== CODE GENERATION COMPLETE ====\")\n",
        "\n",
        "        return new_state\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in hybrid code generation: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "        print(f\"\\n==== ERROR IN CODE GENERATION ====\\n{e}\\n{traceback.format_exc()}\")\n",
        "\n",
        "        # Try to save a version even on error\n",
        "        try:\n",
        "            # Generate version name with timestamp\n",
        "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "            version_name = f\"v_{timestamp}_system_error\"\n",
        "\n",
        "            # Create filenames\n",
        "            csv_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.csv\")\n",
        "            excel_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.xlsx\")\n",
        "\n",
        "            # Save both formats\n",
        "            df.to_csv(csv_filename, index=False)\n",
        "            df.to_excel(excel_filename, index=False, engine='openpyxl')\n",
        "\n",
        "            save_message = f\"✓ Saved dataframe version {version_name}: System error - {str(e)[:100]}\"\n",
        "            print(save_message)\n",
        "            print(f\"  - CSV: {csv_filename}\")\n",
        "            print(f\"  - Excel: {excel_filename}\")\n",
        "        except Exception as save_error:\n",
        "            print(f\"Failed to save error version: {save_error}\")\n",
        "\n",
        "        # Fallback to a generic response\n",
        "        fallback_response = f\"\"\"\n",
        "        I'm sorry, I encountered an issue while generating and executing code for your request.\n",
        "\n",
        "        **Technical Details:** {str(e)}\n",
        "\n",
        "        Could you try asking your question in a different way? For complex analyses, it sometimes helps to break down your request into smaller, more specific questions.\n",
        "        \"\"\"\n",
        "\n",
        "        new_state = dict(state)\n",
        "        new_state[\"final_response\"] = fallback_response\n",
        "\n",
        "        new_messages = state[\"messages\"].copy()\n",
        "        new_messages.append({\"role\": \"assistant\", \"content\": fallback_response})\n",
        "        new_state[\"messages\"] = new_messages\n",
        "\n",
        "        return new_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CFZKl40KcZaV"
      },
      "outputs": [],
      "source": [
        "# Build the LangGraph workflow\n",
        "def create_agentic_rent_roll_analyzer():\n",
        "    \"\"\"Create and return the agentic rent roll analyzer workflow.\"\"\"\n",
        "\n",
        "    # Create the graph\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # Add nodes to the graph\n",
        "    workflow.add_node(\"determine_action\", determine_action)\n",
        "    workflow.add_node(\"ask_clarification\", ask_clarification)\n",
        "    workflow.add_node(\"generate_text_response\", generate_text_response)\n",
        "    workflow.add_node(\"generate_code_and_execute\", generate_code_and_execute)\n",
        "\n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"determine_action\")\n",
        "\n",
        "    # Define conditional edges based on dictionary state values\n",
        "    workflow.add_conditional_edges(\n",
        "        \"determine_action\",\n",
        "        lambda state: \"ask_clarification\" if state.get(\"needs_clarification\") else\n",
        "                      \"generate_code_and_execute\" if state.get(\"generate_code\") else\n",
        "                      \"generate_text_response\"\n",
        "    )\n",
        "\n",
        "    # Add edges to END\n",
        "    workflow.add_edge(\"ask_clarification\", END)\n",
        "    workflow.add_edge(\"generate_text_response\", END)\n",
        "    workflow.add_edge(\"generate_code_and_execute\", END)\n",
        "\n",
        "    # Compile the graph\n",
        "    agentic_analyzer = workflow.compile()\n",
        "\n",
        "    return agentic_analyzer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4mKF1WukcceN"
      },
      "outputs": [],
      "source": [
        "def upload_rent_roll(file, anthropic_api_key, openai_api_key, auto_analyze):\n",
        "    \"\"\"Process the uploaded rent roll file and initialize the chat.\"\"\"\n",
        "    global app_state\n",
        "\n",
        "    logger.info(\"Starting rent roll upload and processing\")\n",
        "\n",
        "    # Use the default API keys if none are provided\n",
        "    anthropic_key = anthropic_api_key if anthropic_api_key else DEFAULT_ANTHROPIC_API_KEY\n",
        "    openai_key = openai_api_key if openai_api_key else DEFAULT_OPENAI_API_KEY\n",
        "    logger.info(\"API keys configured\")\n",
        "\n",
        "    # Validate inputs\n",
        "    if not file:\n",
        "        logger.warning(\"No file uploaded\")\n",
        "        return \"Please upload a rent roll Excel file.\", None, gr.update(visible=False)\n",
        "\n",
        "    try:\n",
        "        # Save the uploaded file to a temporary location\n",
        "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx')\n",
        "        temp_file.close()\n",
        "        file_path = temp_file.name\n",
        "        logger.info(f\"Created temporary file: {file_path}\")\n",
        "\n",
        "        # Copy the uploaded file to our temporary location\n",
        "        with open(file.name, 'rb') as src_file, open(file_path, 'wb') as dst_file:\n",
        "            dst_file.write(src_file.read())\n",
        "        logger.info(\"File copied to temporary location\")\n",
        "\n",
        "        # Use our improved rent roll loader\n",
        "        try:\n",
        "            logger.info(\"Loading rent roll with specialized loader...\")\n",
        "            rent_roll_df = read_rent_roll_simple(file_path)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error with specialized loader: {e}. Falling back to standard loading.\")\n",
        "            # Fallback to basic loading\n",
        "            rent_roll_df = pd.read_excel(file_path)\n",
        "            logger.info(\"Fallback: Loaded rent roll with default pandas settings\")\n",
        "\n",
        "        logger.info(f\"Loaded rent roll data: {len(rent_roll_df)} rows, {len(rent_roll_df.columns)} columns\")\n",
        "\n",
        "        # Auto-analyze with GPT if selected\n",
        "        if auto_analyze:\n",
        "            logger.info(\"Auto-analyze option selected. Calling GPT for analysis...\")\n",
        "            issues_list = analyze_rent_roll_gpt(file_path, openai_key)  # Use OpenAI key for this\n",
        "            logger.info(f\"GPT analysis complete. Found {len(issues_list)} issues.\")\n",
        "        else:\n",
        "            # Create empty issues list if not auto-analyzing\n",
        "            issues_list = []\n",
        "            logger.info(\"No auto-analysis performed.\")\n",
        "\n",
        "        # Initialize the global app state with version tracking\n",
        "        app_state = {\n",
        "            \"df\": rent_roll_df,\n",
        "            \"issues\": issues_list,\n",
        "            \"anthropic_client\": Anthropic(api_key=anthropic_key),\n",
        "            \"openai_client\": OpenAI(api_key=openai_key),\n",
        "            \"system_message\": \"\",  # Will be populated below\n",
        "            \"df_versions\": []  # Initialize empty version registry\n",
        "        }\n",
        "\n",
        "        # Save the initial version\n",
        "        initial_version = save_dataframe_version(rent_roll_df, \"Initial upload - original dataset\")\n",
        "        logger.info(f\"Created initial dataframe version: {initial_version}\")\n",
        "\n",
        "        # Create system message with data understanding\n",
        "        column_info = []\n",
        "        for col in rent_roll_df.columns:\n",
        "            try:\n",
        "                dtype_str = str(rent_roll_df[col].dtype)\n",
        "                column_info.append(f\"- {col}: {dtype_str}\")\n",
        "            except Exception as e:\n",
        "                column_info.append(f\"- {col}: [Error determining type: {str(e)}]\")\n",
        "        column_info_str = \"\\n\".join(column_info)\n",
        "        # Calculate basic stats about the data\n",
        "        data_stats = []\n",
        "        for col in rent_roll_df.columns:\n",
        "            try:\n",
        "                if pd.api.types.is_numeric_dtype(rent_roll_df[col]):\n",
        "                    stat = f\"- {col}: min={rent_roll_df[col].min()}, max={rent_roll_df[col].max()}, mean={rent_roll_df[col].mean():.2f}, null={rent_roll_df[col].isna().sum()}\"\n",
        "                else:\n",
        "                    unique_vals = rent_roll_df[col].nunique()\n",
        "                    stat = f\"- {col}: unique values={unique_vals}, null={rent_roll_df[col].isna().sum()}\"\n",
        "                data_stats.append(stat)\n",
        "            except:\n",
        "                data_stats.append(f\"- {col}: [error calculating stats]\")\n",
        "        data_stats_str = \"\\n\".join(data_stats)\n",
        "\n",
        "        # Format issues for display\n",
        "        issues_text = \"\\n\".join([f\"- {issue}\" for issue in issues_list])\n",
        "\n",
        "        system_message = f\"\"\"\n",
        "        You are a Commercial Real Estate rent roll assistant that has analyzed a rent roll and found the following issues:\n",
        "\n",
        "        {issues_text}\n",
        "\n",
        "        The rent roll data has {len(rent_roll_df)} rows and {len(rent_roll_df.columns)} columns.\n",
        "\n",
        "        Column information:\n",
        "        {column_info_str}\n",
        "\n",
        "        Data statistics:\n",
        "        {data_stats_str}\n",
        "\n",
        "        When helping the user, follow these critical guidelines:\n",
        "        1. DO NOT generate placeholder code with fake column names. Work ONLY with the actual columns from the dataframe.\n",
        "        2. NEVER assume column names that don't exist in the actual data.\n",
        "        3. Always start by examining the first few rows to understand the meaning of each column.\n",
        "        4. If you can't identify which columns contain certain information, clearly state this limitation.\n",
        "        5. DO NOT proceed with analysis using made-up column names that don't exist in the data.\n",
        "\n",
        "        The entire dataframe is available as 'df' in the execution environment.\n",
        "\n",
        "        Important instructions for code and calculations:\n",
        "        1. ALWAYS share your chain of thought reasoning in your responses. For each analysis:\n",
        "          - Begin with \"**Thinking through this step by step:**\" in bold\n",
        "          - Clearly explain your understanding of the request\n",
        "          - Describe your approach to solving the problem\n",
        "          - Outline the data exploration steps you'll take\n",
        "          - Explain why you're choosing specific columns and methods\n",
        "          - Discuss any challenges you anticipate with the data structure\n",
        "          This chain of thought should be visible to the user in your chat responses.\n",
        "        \"\"\"\n",
        "\n",
        "        # Save the system message to the app state\n",
        "        app_state[\"system_message\"] = system_message\n",
        "\n",
        "        # Clean up the temporary file\n",
        "        os.unlink(file_path)\n",
        "        logger.info(\"Temporary file removed\")\n",
        "\n",
        "        # Generate a preview of the data and issues\n",
        "        preview_html = f\"\"\"\n",
        "        <h3>Rent Roll Preview</h3>\n",
        "        <p>Successfully loaded rent roll with {len(rent_roll_df)} rows and {len(rent_roll_df.columns)} columns.</p>\n",
        "        {rent_roll_df.head(5).fillna('').to_html(index=False)}\n",
        "\n",
        "        <h3>Identified Issues</h3>\n",
        "        <ol>\n",
        "        \"\"\"\n",
        "\n",
        "        # Format each issue for the HTML preview\n",
        "        for issue in issues_list:\n",
        "            # If issue starts with a number (like \"1. Issue\"), strip the number\n",
        "            if issue and issue[0].isdigit() and \". \" in issue[:5]:\n",
        "                issue = issue[issue.find(\". \")+2:]\n",
        "            preview_html += f\"<li>{issue}</li>\"\n",
        "\n",
        "        preview_html += \"\"\"\n",
        "        </ol>\n",
        "        <p>You can now start asking questions in the chat below!</p>\n",
        "        <p><strong>Note:</strong> This application uses GPT-4 for decision making and text responses,\n",
        "        and Claude AI specifically for code generation and execution.</p>\n",
        "        \"\"\"\n",
        "        version_choices = get_version_choices()\n",
        "        # Make the chat interface visible\n",
        "        logger.info(\"Setup complete. Ready for chat interaction.\")\n",
        "        return (\n",
        "            \"Rent roll loaded successfully! You can now start chatting.\",\n",
        "            preview_html,\n",
        "            gr.update(visible=True),  # chatbot visibility\n",
        "            gr.update(choices=version_choices, value=version_choices[-1] if version_choices else None)  # version dropdown\n",
        "        )\n",
        "\n",
        "\n",
        "    # Also update the error return:\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error during rent roll processing: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "        if 'file_path' in locals() and os.path.exists(file_path):\n",
        "            os.unlink(file_path)\n",
        "            logger.info(\"Cleaned up temporary file after error\")\n",
        "        return f\"Error: {str(e)}\", None, gr.update(visible=False), gr.update(choices=[], value=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g86vl7iVq7lV"
      },
      "outputs": [],
      "source": [
        "def load_latest_version_for_editing():\n",
        "    \"\"\"Load the most recent version of the dataframe for editing\"\"\"\n",
        "    global app_state\n",
        "\n",
        "    if app_state is None or app_state[\"df\"] is None:\n",
        "        return None, \"No data loaded. Please upload a rent roll first.\"\n",
        "\n",
        "    try:\n",
        "        # Use the current dataframe (which is the latest)\n",
        "        df = app_state[\"df\"].copy()\n",
        "        df = df.fillna('')\n",
        "        # Get version info\n",
        "        if app_state[\"df_versions\"]:\n",
        "            latest_version = app_state[\"df_versions\"][-1]\n",
        "            version_info = f\"Loaded version: {latest_version['name']} - {latest_version['description']}\"\n",
        "        else:\n",
        "            version_info = \"Loaded current data (no versions saved yet)\"\n",
        "\n",
        "        logger.info(f\"Loaded dataframe for editing: {df.shape}\")\n",
        "        return df, version_info\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading data for editing: {e}\")\n",
        "        return None, f\"Error loading data: {str(e)}\"\n",
        "\n",
        "def save_edited_dataframe(edited_df, description):\n",
        "    \"\"\"Save the edited dataframe as a new version\"\"\"\n",
        "    global app_state\n",
        "\n",
        "    if edited_df is None or edited_df.empty:\n",
        "        return \"No data to save\", gr.update()\n",
        "\n",
        "    try:\n",
        "        # Convert the edited dataframe to proper pandas DataFrame if needed\n",
        "        if not isinstance(edited_df, pd.DataFrame):\n",
        "            edited_df = pd.DataFrame(edited_df)\n",
        "\n",
        "        # Generate a meaningful description\n",
        "        if not description:\n",
        "            description = \"Manual edits via data editor\"\n",
        "\n",
        "        # Save as new version\n",
        "        version_name = save_dataframe_version(edited_df, description)\n",
        "\n",
        "        # Update the app state with the edited dataframe\n",
        "        app_state[\"df\"] = edited_df\n",
        "\n",
        "        # Log the changes\n",
        "        logger.info(f\"Saved edited dataframe as version {version_name}\")\n",
        "\n",
        "        # Return success message and update the view\n",
        "        return f\"✅ Successfully saved as version {version_name}\", gr.update(value=edited_df)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error saving edited dataframe: {e}\")\n",
        "        return f\"❌ Error saving: {str(e)}\", gr.update()\n",
        "\n",
        "def load_specific_version(version_name):\n",
        "    \"\"\"Load a specific version for editing\"\"\"\n",
        "    global app_state\n",
        "\n",
        "    if not version_name:\n",
        "        return None, \"Please select a version to load\"\n",
        "\n",
        "    try:\n",
        "        # Find the version file\n",
        "        versions_dir = \"rent_roll_versions\"\n",
        "        csv_filename = os.path.join(versions_dir, f\"rent_roll_{version_name}.csv\")\n",
        "\n",
        "        if os.path.exists(csv_filename):\n",
        "            df = pd.read_csv(csv_filename)\n",
        "            df = df.fillna('')\n",
        "            logger.info(f\"Loaded version {version_name} for editing\")\n",
        "            return df, f\"Loaded version: {version_name}\"\n",
        "        else:\n",
        "            return None, f\"Version file not found: {version_name}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error loading version {version_name}: {e}\")\n",
        "        return None, f\"Error loading version: {str(e)}\"\n",
        "\n",
        "def get_version_choices():\n",
        "    \"\"\"Get list of available versions for dropdown\"\"\"\n",
        "    global app_state\n",
        "\n",
        "    if app_state and \"df_versions\" in app_state and app_state[\"df_versions\"]:\n",
        "        choices = []\n",
        "        for i, version in enumerate(app_state[\"df_versions\"]):\n",
        "            status = \"\"\n",
        "            if i == 0:\n",
        "                status = \" (ORIGINAL)\"\n",
        "            elif i == len(app_state[\"df_versions\"]) - 1:\n",
        "                status = \" (LATEST)\"\n",
        "\n",
        "            choices.append(f\"{version['name']}{status}\")\n",
        "        return choices\n",
        "    return []\n",
        "\n",
        "def refresh_version_dropdown():\n",
        "    \"\"\"Refresh the version dropdown choices\"\"\"\n",
        "    choices = get_version_choices()\n",
        "    if choices:\n",
        "        return gr.update(choices=choices, value=choices[-1])  # Default to latest\n",
        "    return gr.update(choices=[], value=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "D4Xebkjsdnm_"
      },
      "outputs": [],
      "source": [
        "# Global state for the application (Not part of graph state)\n",
        "app_state = {\n",
        "    \"df\": None,\n",
        "    \"anthropic_client\": None,\n",
        "    \"openai_client\": None,  # Added for GPT-4\n",
        "    \"issues\": [],\n",
        "    \"system_message\": \"\"\n",
        "}\n",
        "\n",
        "# Chat processing function using the agentic workflow\n",
        "def chat(message, history):\n",
        "    \"\"\"Process user message through the agentic workflow and get response.\"\"\"\n",
        "    global app_state\n",
        "\n",
        "    logger.info(f\"Received chat message: {message[:50]}...\")\n",
        "\n",
        "    if app_state is None or app_state[\"df\"] is None:\n",
        "        logger.warning(\"Chat attempted before setup is complete\")\n",
        "        return history + [(message, \"Please upload a rent roll file and set up your API keys first.\")]\n",
        "\n",
        "    # Get previous messages from history\n",
        "    prev_messages = []\n",
        "    if history:\n",
        "        for user_msg, assistant_msg in history:\n",
        "            prev_messages.append({\"role\": \"user\", \"content\": user_msg})\n",
        "            prev_messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
        "\n",
        "    # Create message list without system message\n",
        "    all_messages = []\n",
        "    all_messages.extend(prev_messages)\n",
        "\n",
        "    # Add the current user message\n",
        "    all_messages.append({\"role\": \"user\", \"content\": message})\n",
        "\n",
        "    # Create a state dictionary for the graph\n",
        "    state = {\n",
        "        \"messages\": all_messages,\n",
        "        \"system_message\": app_state[\"system_message\"],  # Store separately\n",
        "        \"df\": app_state[\"df\"],\n",
        "        \"issues\": app_state[\"issues\"],\n",
        "        \"needs_clarification\": False,\n",
        "        \"generate_code\": False,\n",
        "        \"execution_plan\": None,\n",
        "        \"clarification_question\": None,\n",
        "        \"code_execution_results\": None,\n",
        "        \"final_response\": None,\n",
        "        # Pass the API clients to the state\n",
        "        \"anthropic_client\": app_state[\"anthropic_client\"],\n",
        "        \"openai_client\": app_state[\"openai_client\"]\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Create the workflow if not already created\n",
        "        if not hasattr(chat, \"workflow\"):\n",
        "            chat.workflow = create_agentic_rent_roll_analyzer()\n",
        "            logger.info(\"Created agentic workflow\")\n",
        "\n",
        "        # Run the workflow with the current state\n",
        "        logger.info(\"Running agentic workflow\")\n",
        "        result = chat.workflow.invoke(state)\n",
        "\n",
        "        # Get the final response from the result state\n",
        "        final_response = result.get(\"final_response\", \"I'm sorry, I couldn't process your request.\")\n",
        "        logger.info(f\"Received final response from workflow: {final_response[:50]}...\")\n",
        "\n",
        "        # Use the correct format for Gradio chatbot - must be a list of tuples (user_msg, bot_msg)\n",
        "        history_list = list(history) if history else []\n",
        "        history_list.append((message, final_response))\n",
        "\n",
        "        logger.info(\"Chat response processing complete\")\n",
        "        return history_list\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing chat: {e}\")\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "        # Handle errors properly in the chat history format\n",
        "        history_list = list(history) if history else []\n",
        "        error_message = f\"Error getting response: {str(e)}\"\n",
        "        history_list.append((message, error_message))\n",
        "        return history_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2jZK7cESeNDd"
      },
      "outputs": [],
      "source": [
        "def view_data():\n",
        "    \"\"\"Return a preview of the rent roll data.\"\"\"\n",
        "    global app_state  # Use app_state instead of agent_state\n",
        "\n",
        "    logger.info(\"View data requested\")\n",
        "\n",
        "    if app_state is None or app_state[\"df\"] is None:  # Note the dictionary access with [\"df\"]\n",
        "        logger.warning(\"View data requested but no data is loaded\")\n",
        "        return \"No rent roll data loaded yet.\"\n",
        "\n",
        "    # Generate HTML representation of the dataframe\n",
        "    logger.info(f\"Generating HTML preview of data with {len(app_state['df'])} rows\")\n",
        "    html = f\"\"\"\n",
        "    <h3>Rent Roll Data</h3>\n",
        "    <p>{len(app_state['df'])} rows × {len(app_state['df'].columns)} columns</p>\n",
        "    {app_state['df'].head(10).fillna('').to_html(index=False)}\n",
        "    \"\"\"\n",
        "\n",
        "    return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jho5cKJ9ehpb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clear_chat():\n",
        "    \"\"\"Reset the chat history.\"\"\"\n",
        "    logger.info(\"Clearing chat history\")\n",
        "    return []  # Return empty list for Gradio chat history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "I6ofDGmDz8n-"
      },
      "outputs": [],
      "source": [
        "def view_dataframe_versions():\n",
        "    \"\"\"Return HTML showing all versions of the rent roll dataframe.\"\"\"\n",
        "    global app_state\n",
        "    logger.info(\"View dataframe versions requested\")\n",
        "\n",
        "    versions_dir = \"rent_roll_versions\"\n",
        "\n",
        "    if not os.path.exists(versions_dir):\n",
        "        logger.warning(\"No versions directory found\")\n",
        "        return \"No version history found. Please save a version first.\"\n",
        "\n",
        "    # Get all files in the versions directory\n",
        "    try:\n",
        "        all_files = os.listdir(versions_dir)\n",
        "        # Match any CSV file containing rent_roll in the name\n",
        "        version_files = [f for f in all_files if f.endswith('.csv') and 'rent_roll' in f]\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error reading versions directory: {e}\")\n",
        "        return f\"Error listing versions: {str(e)}\"\n",
        "\n",
        "    if not version_files:\n",
        "        logger.warning(\"No version files found in directory\")\n",
        "        return f\"No version files found in the versions directory ({versions_dir}).\"\n",
        "\n",
        "    # Extract version information\n",
        "    versions = []\n",
        "    for file in version_files:\n",
        "        # Extract the version name from the filename\n",
        "        if file.startswith('rent_roll_v_'):\n",
        "            version_name = file.replace('rent_roll_', '').replace('.csv', '')\n",
        "        else:\n",
        "            version_name = os.path.splitext(file)[0].replace('rent_roll_', '')\n",
        "\n",
        "        # Get file stats\n",
        "        try:\n",
        "            file_path = os.path.join(versions_dir, file)\n",
        "            file_stats = os.stat(file_path)\n",
        "            file_size = file_stats.st_size\n",
        "            modified_time = datetime.fromtimestamp(file_stats.st_mtime).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "            # Try to get row and column counts\n",
        "            df_info = \"\"\n",
        "            try:\n",
        "                temp_df = pd.read_csv(file_path)\n",
        "                df_info = f\"{len(temp_df)} rows × {len(temp_df.columns)} columns\"\n",
        "            except:\n",
        "                df_info = \"Unable to read file\"\n",
        "\n",
        "            # If we have version info in app_state\n",
        "            description = \"\"\n",
        "            is_original = False\n",
        "\n",
        "            for v in app_state.get(\"df_versions\", []):\n",
        "                if v.get(\"name\") == version_name:\n",
        "                    description = v.get(\"description\", \"\")\n",
        "                    is_original = v.get(\"is_original\", False)\n",
        "                    break\n",
        "\n",
        "            # If not found in app_state, use fallback description\n",
        "            if not description and os.path.exists(file_path):\n",
        "                description = \"Found in directory\"\n",
        "\n",
        "            versions.append({\n",
        "                'version_name': version_name,\n",
        "                'file_size': file_size,\n",
        "                'modified_time': modified_time,\n",
        "                'df_info': df_info,\n",
        "                'description': description,\n",
        "                'is_original': is_original,\n",
        "                'file_path': file_path\n",
        "            })\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing version file {file}: {e}\")\n",
        "            versions.append({\n",
        "                'version_name': version_name,\n",
        "                'file_size': 0,\n",
        "                'modified_time': 'Error',\n",
        "                'df_info': f\"Error: {str(e)}\",\n",
        "                'description': '',\n",
        "                'is_original': False,\n",
        "                'file_path': os.path.join(versions_dir, file)\n",
        "            })\n",
        "\n",
        "    # Sort versions by modification time\n",
        "    versions.sort(key=lambda x: x['modified_time'])\n",
        "\n",
        "    # Create basic HTML table without zebra striping\n",
        "    html = \"\"\"\n",
        "    <h3 style=\"color: white;\">Rent Roll Dataframe Version History</h3>\n",
        "    \"\"\"\n",
        "\n",
        "    html += f\"\"\"\n",
        "    <p style=\"color: white;\">Found {len(versions)} version(s) in {versions_dir}</p>\n",
        "    <table border=\"1\" cellpadding=\"5\" cellspacing=\"0\" style=\"width: 100%; border-collapse: collapse; color: white;\">\n",
        "        <thead style=\"background-color: #009879;\">\n",
        "            <tr>\n",
        "                <th style=\"text-align: left; padding: 10px;\">Version Name</th>\n",
        "                <th style=\"text-align: left; padding: 10px;\">Status</th>\n",
        "                <th style=\"text-align: left; padding: 10px;\">Created</th>\n",
        "                <th style=\"text-align: left; padding: 10px;\">Size</th>\n",
        "                <th style=\"text-align: left; padding: 10px;\">Data</th>\n",
        "                <th style=\"text-align: left; padding: 10px;\">Description</th>\n",
        "            </tr>\n",
        "        </thead>\n",
        "        <tbody>\n",
        "    \"\"\"\n",
        "\n",
        "    for i, v in enumerate(versions):\n",
        "        # No alternating rows - all cells have the same background and text color\n",
        "        # Always use dark background with white text for all rows\n",
        "\n",
        "        # Determine status badge\n",
        "        if i == 0 or v.get('is_original'):\n",
        "            status_html = '<span style=\"background-color: #3949ab; color: white; padding: 3px 6px; border-radius: 3px; display: inline-block;\">ORIGINAL</span>'\n",
        "        elif i == len(versions) - 1:\n",
        "            status_html = '<span style=\"background-color: #43a047; color: white; padding: 3px 6px; border-radius: 3px; display: inline-block;\">LATEST</span>'\n",
        "        else:\n",
        "            # Middle version with orange badge\n",
        "            status_html = f'<span style=\"background-color: #f57c00; color: white; padding: 3px 6px; border-radius: 3px; display: inline-block;\">v{i+1}</span>'\n",
        "\n",
        "        # All rows have dark background and white text\n",
        "        html += f\"\"\"\n",
        "        <tr style=\"background-color: #25292e; color: white; border-bottom: 1px solid #333;\">\n",
        "            <td style=\"padding: 10px;\"><code style=\"font-family: monospace; font-weight: bold;\">{v['version_name']}</code></td>\n",
        "            <td style=\"padding: 10px;\">{status_html}</td>\n",
        "            <td style=\"padding: 10px;\">{v['modified_time']}</td>\n",
        "            <td style=\"padding: 10px;\">{round(v['file_size']/1024, 2)} KB</td>\n",
        "            <td style=\"padding: 10px;\">{v['df_info']}</td>\n",
        "            <td style=\"padding: 10px;\">{v['description']}</td>\n",
        "        </tr>\n",
        "        \"\"\"\n",
        "\n",
        "    html += \"\"\"\n",
        "        </tbody>\n",
        "    </table>\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(f\"Generated version history display with {len(versions)} versions\")\n",
        "    return html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYiRx9fvejLP",
        "outputId": "3d54b383-1ce9-45f4-d086-fa1243439357"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-e4d2627bcabc>:53: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Agentic Rent Roll Analysis Chat\", height=500, type=\"tuples\")\n"
          ]
        }
      ],
      "source": [
        "# Initialize the global agent state\n",
        "agent_state = None\n",
        "custom_css = \"\"\"\n",
        ".chatbot-container .message-wrap .message.bot pre {\n",
        "    white-space: pre !important;\n",
        "    overflow-x: auto !important;\n",
        "    max-width: 100% !important;\n",
        "}\n",
        ".chatbot-container .message-wrap .message.bot code {\n",
        "    white-space: pre !important;\n",
        "}\n",
        "\"\"\"\n",
        "# Define the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\"), css=custom_css) as demo:\n",
        "    gr.Markdown(\"# Agentic Commercial Real Estate Rent Roll Analyzer\")\n",
        "    gr.Markdown(\"## Hybrid AI System: GPT-4 for Decision Making & Claude for Code Generation\")\n",
        "\n",
        "    with gr.Tab(\"Setup\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                file_input = gr.File(label=\"Upload Rent Roll Excel File (.xlsx, .xls)\")\n",
        "\n",
        "                # Add separate API key inputs for OpenAI and Anthropic\n",
        "                anthropic_api_key = gr.Textbox(\n",
        "                    label=\"Anthropic API Key (Optional - for code generation)\",\n",
        "                    placeholder=\"Leave blank to use the default API key\",\n",
        "                    type=\"password\"\n",
        "                )\n",
        "\n",
        "                openai_api_key = gr.Textbox(\n",
        "                    label=\"OpenAI API Key (Optional - for decision making and text responses)\",\n",
        "                    placeholder=\"Leave blank to use the default API key\",\n",
        "                    type=\"password\"\n",
        "                )\n",
        "\n",
        "                # Updated auto-analyze checkbox\n",
        "                auto_analyze = gr.Checkbox(\n",
        "                    label=\"Automatically analyze for issues using GPT-4\",\n",
        "                    value=True,\n",
        "                    info=\"When checked, GPT-4 will automatically identify issues in your rent roll\"\n",
        "                )\n",
        "\n",
        "                upload_button = gr.Button(\"Load Rent Roll & Start Chat\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column():\n",
        "                result = gr.Textbox(label=\"Status\")\n",
        "                preview = gr.HTML(label=\"Data Preview\")\n",
        "\n",
        "    with gr.Tab(\"Chat\"):\n",
        "        # Changed button text to reflect version history functionality\n",
        "        view_versions_btn = gr.Button(\"View Version History\")\n",
        "        data_view = gr.HTML()\n",
        "        chatbot = gr.Chatbot(label=\"Agentic Rent Roll Analysis Chat\", height=500, type=\"tuples\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=4):\n",
        "                msg = gr.Textbox(label=\"Your question\", placeholder=\"Ask about the rent roll...\", lines=2)\n",
        "            with gr.Column(scale=1):\n",
        "                send_btn = gr.Button(\"Send\", variant=\"primary\")\n",
        "\n",
        "        clear_btn = gr.Button(\"Clear Chat History\")\n",
        "\n",
        "        # Set up event handlers with proper return values for Gradio chatbot\n",
        "        msg.submit(\n",
        "            chat,\n",
        "            inputs=[msg, chatbot],\n",
        "            outputs=[chatbot]\n",
        "        ).then(\n",
        "            lambda: \"\", None, msg  # Clear the message box after sending\n",
        "        )\n",
        "\n",
        "        send_btn.click(\n",
        "            chat,\n",
        "            inputs=[msg, chatbot],\n",
        "            outputs=[chatbot]\n",
        "        ).then(\n",
        "            lambda: \"\", None, msg  # Clear the message box after sending\n",
        "        )\n",
        "\n",
        "        clear_btn.click(clear_chat, None, chatbot)\n",
        "        # Changed to use the new version history function\n",
        "        view_versions_btn.click(view_dataframe_versions, None, data_view)\n",
        "\n",
        "    with gr.Tab(\"Edit Data\"):\n",
        "        gr.Markdown(\"\"\"\n",
        "        ### 📝 Edit Rent Roll Data\n",
        "\n",
        "        You can directly edit cells in the table below, just like in Excel.\n",
        "        - Click on any cell to edit it\n",
        "        - Use Tab or arrow keys to navigate\n",
        "        - Changes are not saved until you click \"Save as New Version\"\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3):\n",
        "                # Version selector\n",
        "                version_dropdown = gr.Dropdown(\n",
        "                    label=\"Select Version to Edit\",\n",
        "                    choices=get_version_choices(),\n",
        "                    value=None,\n",
        "                    interactive=True\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                refresh_versions_btn = gr.Button(\"🔄 Refresh Versions\", size=\"sm\")\n",
        "                load_version_btn = gr.Button(\"📂 Load Selected Version\", variant=\"primary\")\n",
        "\n",
        "        # Status display\n",
        "        edit_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "        # The editable dataframe\n",
        "        editable_df = gr.Dataframe(\n",
        "            label=\"Editable Data (Click any cell to edit)\",\n",
        "            interactive=True,  # This makes it editable!\n",
        "            wrap=True,\n",
        "            max_height=500,  # Changed from height to max_height\n",
        "            column_widths=[\"100px\"] * 20,  # Adjust based on your needs\n",
        "        )\n",
        "\n",
        "        # Save controls\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=3):\n",
        "                save_description = gr.Textbox(\n",
        "                    label=\"Description of Changes\",\n",
        "                    placeholder=\"e.g., 'Updated rent for units 101-105' or 'Corrected typos in tenant names'\",\n",
        "                    lines=2\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                save_changes_btn = gr.Button(\"💾 Save as New Version\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        save_status = gr.Textbox(label=\"Save Status\", interactive=False)\n",
        "\n",
        "        # Quick actions section\n",
        "        with gr.Accordion(\"Quick Actions\", open=False):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### Bulk Operations\n",
        "            Use these buttons for common bulk edits:\n",
        "            \"\"\")\n",
        "\n",
        "            with gr.Row():\n",
        "                # Add quick action buttons here in future\n",
        "                gr.Button(\"🧹 Clean Empty Rows\", size=\"sm\", interactive=False)\n",
        "                gr.Button(\"💵 Round All Currency\", size=\"sm\", interactive=False)\n",
        "                gr.Button(\"📅 Fix Date Formats\", size=\"sm\", interactive=False)\n",
        "                gr.Button(\"🔢 Recalculate Totals\", size=\"sm\", interactive=False)\n",
        "\n",
        "        # Instructions\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        ### 💡 How to Use:\n",
        "        1. **Load Data**: Click \"Load Selected Version\" to load a version for editing\n",
        "        2. **Edit Cells**: Click on any cell and type to edit (just like Excel!)\n",
        "        3. **Navigate**: Use Tab, Enter, or arrow keys to move between cells\n",
        "        4. **Save Changes**: Enter a description and click \"Save as New Version\"\n",
        "\n",
        "        ### ⚠️ Important Notes:\n",
        "        - Changes are NOT auto-saved - you must click \"Save as New Version\"\n",
        "        - Each save creates a new version, preserving the original\n",
        "        - Large datasets may be slow to edit - consider using filters\n",
        "        - To undo changes before saving, simply reload the version\n",
        "        \"\"\")\n",
        "\n",
        "        # Event handlers for Edit Data tab\n",
        "        refresh_versions_btn.click(\n",
        "            refresh_version_dropdown,\n",
        "            outputs=[version_dropdown]\n",
        "        )\n",
        "\n",
        "        load_version_btn.click(\n",
        "            lambda version: load_specific_version(version.split(\" (\")[0]) if version else (None, \"No version selected\"),\n",
        "            inputs=[version_dropdown],\n",
        "            outputs=[editable_df, edit_status]\n",
        "        )\n",
        "\n",
        "        save_changes_btn.click(\n",
        "            save_edited_dataframe,\n",
        "            inputs=[editable_df, save_description],\n",
        "            outputs=[save_status, editable_df]\n",
        "        ).then(\n",
        "            refresh_version_dropdown,  # Refresh the dropdown after saving\n",
        "            outputs=[version_dropdown]\n",
        "        )\n",
        "\n",
        "    # Initially hide the chat interface\n",
        "    chatbot.visible = False\n",
        "\n",
        "    # Updated upload button event with both API keys and version dropdown\n",
        "    upload_button.click(\n",
        "        upload_rent_roll,\n",
        "        inputs=[file_input, anthropic_api_key, openai_api_key, auto_analyze],\n",
        "        outputs=[result, preview, chatbot, version_dropdown]  # Added version_dropdown\n",
        "    )\n",
        "\n",
        "    # Updated style and help info\n",
        "    gr.Markdown(\"\"\"\n",
        "    ## How to use this Agentic Rent Roll Analyzer:\n",
        "\n",
        "    1. In the **Setup** tab, upload your rent roll Excel file\n",
        "    2. Default API keys are already set, but you can provide your own if needed:\n",
        "       - OpenAI API key is used for decision making and text responses\n",
        "       - Anthropic API key is used for code generation and execution\n",
        "    3. Choose whether to automatically analyze issues (recommended)\n",
        "    4. Click \"Load Rent Roll & Start Chat\" to proceed\n",
        "    5. Switch to the **Chat** tab to start asking questions about your rent roll\n",
        "    6. Use the **Edit Data** tab to make direct edits to your data (like Excel)\n",
        "    7. Use the \"View Version History\" button to see all saved versions of your dataframe\n",
        "\n",
        "    ### Key Features:\n",
        "\n",
        "    - **Hybrid AI approach**:\n",
        "      - GPT-4 handles decision making and text responses\n",
        "      - Claude AI specialized for code generation and execution\n",
        "\n",
        "    - **Intelligent response mode**: The system automatically decides whether to:\n",
        "      - Ask clarifying questions when your query is ambiguous\n",
        "      - Provide simple explanations for straightforward questions\n",
        "      - Generate and execute code for complex analytical questions\n",
        "\n",
        "    - **Direct cell editing** (NEW):\n",
        "      - Edit cells directly like in Excel\n",
        "      - Load any version for editing\n",
        "      - Save changes as new versions\n",
        "      - Complete version history maintained\n",
        "\n",
        "    - **Version tracking**: The system maintains a history of all dataframe versions\n",
        "      - Original version is always the first one saved\n",
        "      - Latest version is the most recent one saved\n",
        "      - Specific versions can be referenced by name\n",
        "      - All versions saved in both CSV and Excel formats\n",
        "\n",
        "    - **Adaptive analysis**: Get insights tailored to your specific needs without unnecessary complexity\n",
        "\n",
        "    - **Conversational interface**: Chat naturally about your rent roll data\n",
        "\n",
        "    The assistant can analyze your rent roll data, identify issues, and suggest solutions - all in a natural conversational format.\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 767
        },
        "id": "TYFJGIGney3s",
        "outputId": "b0c6c817-0a5b-4849-ad67-cdc9387ef939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://152cfbb8559a528965.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://152cfbb8559a528965.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:rent_roll_analyzer:Could not find header row with 'Current' marker. Falling back to standard loading.\n",
            "WARNING:rent_roll_analyzer:Could not find header row with 'Current' marker. Falling back to standard loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved dataframe version v_20250525_012804: Initial upload - original dataset\n",
            "  - CSV: rent_roll_versions/rent_roll_v_20250525_012804.csv\n",
            "  - Excel: rent_roll_versions/rent_roll_v_20250525_012804.xlsx\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1965: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  state[block._id] = block.__class__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Run the application\n",
        "if __name__ == \"__main__\":\n",
        "    logger.info(\"Starting Agentic Rent Roll Analyzer application\")\n",
        "    demo.launch(debug=True)\n",
        "    logger.info(\"Application shutdown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bz22BvOOezGk"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/rent_roll_versions_older_versions2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jetTVWA97W6l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc-75XeTtyKI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
